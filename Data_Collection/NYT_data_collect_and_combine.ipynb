{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import urllib.request\n",
    "import glob\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "##############################################################################\n",
    "This function will return New York Times urls from 2019 for the given keyword.\n",
    "##############################################################################\n",
    "'''\n",
    "def nyt_url_list(keyword):\n",
    "    \n",
    "    #Get around 125-150 nyt urls for the given keyword from 2019\n",
    "    url_list = [] #stores urls as a list\n",
    "    for pagenum in range(1, 15):\n",
    "        time.sleep(10)  #Sleep to avoid hitting the per minute rate\n",
    "        url = \"https://api.nytimes.com/svc/search/v2/articlesearch.json?q=\"+str(keyword)+\"&begin_date=20190101&page=\"+str(pagenum)+\"&api-key=flkAlABqreineiWdn9AJjGRuu4QAsknD\"\n",
    "        resp = requests.get(url)\n",
    "        data = json.loads(resp.text)\n",
    "        for item in data[\"response\"][\"docs\"]:\n",
    "            url_list.append(item[\"web_url\"])\n",
    "            \n",
    "    return url_list        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "############################################################################################\n",
    "This function will take New York Times urls as input, \n",
    "extracts paragraphs from each url content and dumps it in to a created text file\n",
    "############################################################################################\n",
    "'''\n",
    "def getArticlesText(url_list, filename):\n",
    "    \n",
    "    text_list = [] #stores articles text\n",
    "    for url in url_list:\n",
    "        try:\n",
    "            r = urllib.request.urlopen(url).read()\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            soup = BeautifulSoup(r, 'lxml')\n",
    "            paras = soup.findAll('p')\n",
    "            text = \" \"\n",
    "            for tag in paras:\n",
    "                text = text + tag.getText()\n",
    "            text_list.append(text)\n",
    "            \n",
    "    #Create a text file of given name and store the articles text in that file.\n",
    "    df = pd.DataFrame(text_list)\n",
    "    df.to_csv('../Data/NYT/'+str(filename)+'.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_topics = [\"Jeff+Bezos\", \"Mark+Zuckerberg\", \"Elon+Musk\", \"Pichai\", \"Tim+Cook\"]\n",
    "\n",
    "for keyword in sub_topics:\n",
    "    filename = \"NYT_\"+ str(keyword.replace('+', ''))\n",
    "    urls = nyt_url_list(keyword)\n",
    "    getArticlesText(urls, filename)\n",
    "    time.sleep(60) #sleep for a minute before collecting the next topic articles  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all sub-topics articles into a single text file which is passed as input to MR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_files = glob.glob('../Data/NYT/*.txt')\n",
    "combined_file = '../Data/NYT\\\\NYT_articles.txt'\n",
    "\n",
    "if combined_file in read_files:\n",
    "    read_files.remove(combined_file)\n",
    "    \n",
    "with open('../Data/NYT/NYT_articles.txt', 'wb') as out:\n",
    "    for file in read_files:\n",
    "        with open(file, 'rb') as f:\n",
    "            out.write(f.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
